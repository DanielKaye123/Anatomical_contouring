{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import shutil\n",
    "from typing import Tuple\n",
    "from batchgenerators.utilities.file_and_folder_operations import save_json, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/vol/biomedic3/bglocker/radiotherapy/kat100/nifti\"\n",
    "target_base = \"/vol/bitbucket/djk18/nnUnet_models/nnUNet_raw_data\"\n",
    "\n",
    "\n",
    "\n",
    "# Also dataset 502_ctv -> this includes same classes as 503 but with regions on bowels (not fem heads)\n",
    "def setup_dataset503(): \n",
    "    #Standard multiclass\n",
    "    global task_name, masks\n",
    "    task_name = \"Dataset503\"\n",
    "    masks = [\"Bones\", \"FemoralHead_L\", \"FemoralHead_R\", \"Bladder\", \"Anorectum\", \"Bowel-bag\", \"Bowel-loops\", \"CTVp\"]\n",
    "\n",
    "# Not used\n",
    "\n",
    "# def setup_dataset504():\n",
    "#     # regions \n",
    "#     global task_name, masks \n",
    "#     task_name = \"Dataset504\"\n",
    "#     masks = [\"Bones\", \"FemoralHead_L\", \"FemoralHead_R\", \"Bladder\", \"Anorectum\", \"Bowel-bag\", \"Bowel-loops\", \"CTVp\"]\n",
    "\n",
    "\n",
    "def setup_dataset505():\n",
    "    # Standard Multiclass - Used for experiment 1 in report\n",
    "    global task_name, masks\n",
    "    task_name = \"Dataset505\"\n",
    "    masks = [\"Bones\", \"FemoralHead\", \"Bladder\", \"Anorectum\", \"Bowel-bag\", \"Bowel-loops\", \"CTVp\"]\n",
    "\n",
    "def setup_dataset506():\n",
    "    # regions - used for experiment 1 in report\n",
    "    global task_name, masks\n",
    "    task_name = \"Dataset506\"\n",
    "    masks = [\"Bones\", \"FemoralHead\", \"Bladder\", \"Anorectum\", \"Bowel-bag\", \"Bowel-loops\", \"CTVp\"]\n",
    "\n",
    "\n",
    "def setup_dataset507(): \n",
    "    # used for experiment 2. This is the ensemble\n",
    "    global task_name, masks\n",
    "    task_name = \"Dataset507\"\n",
    "    masks = [\"CTVn\", \"CTVp\", \"Anorectum\"]\n",
    "\n",
    "setup_dataset507()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_set():\n",
    "  sample_names = sorted(os.listdir(data_dir))\n",
    "  return sample_names[:80]\n",
    "\n",
    "def get_test_set():\n",
    "  sample_names = sorted(os.listdir(data_dir))\n",
    "  return sample_names[80:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_structure(task_path):\n",
    "  isExist = os.path.exists(task_path)\n",
    "  if not isExist:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(task_path)\n",
    "   os.makedirs(task_path + \"/imagesTr\")\n",
    "   os.makedirs(task_path + \"/imagesTs\")\n",
    "   os.makedirs(task_path + \"/labelsTr\")\n",
    "   print(\"The new directory is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'FemoralHead' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/homes/djk18/Anatomical_contouring/pre_processing_nnUNet.ipynb Cell 5\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btexel11/homes/djk18/Anatomical_contouring/pre_processing_nnUNet.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m         shutil\u001b[39m.\u001b[39mcopyfile(image_path, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(target_base, task_name, \u001b[39m\"\u001b[39m\u001b[39mimagesTs\u001b[39m\u001b[39m\"\u001b[39m,  patient_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_0000.nii.gz\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btexel11/homes/djk18/Anatomical_contouring/pre_processing_nnUNet.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m#create_dataset(data_dir)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btexel11/homes/djk18/Anatomical_contouring/pre_processing_nnUNet.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m create_dataset(\u001b[39m\"\u001b[39;49m\u001b[39m/vol/bitbucket/djk18/dataset/downsample_2m_isotropic\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/homes/djk18/Anatomical_contouring/pre_processing_nnUNet.ipynb Cell 5\u001b[0m in \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btexel11/homes/djk18/Anatomical_contouring/pre_processing_nnUNet.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m create_folder_structure(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(target_base, task_name))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btexel11/homes/djk18/Anatomical_contouring/pre_processing_nnUNet.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m num_masks \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(masks) \n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btexel11/homes/djk18/Anatomical_contouring/pre_processing_nnUNet.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m fem_head_index_in_list \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(masks\u001b[39m.\u001b[39;49mindex(\u001b[39m\"\u001b[39;49m\u001b[39mFemoralHead\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btexel11/homes/djk18/Anatomical_contouring/pre_processing_nnUNet.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m patient_name \u001b[39min\u001b[39;00m get_train_set():\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btexel11/homes/djk18/Anatomical_contouring/pre_processing_nnUNet.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(patient_name)\n",
      "\u001b[0;31mValueError\u001b[0m: 'FemoralHead' is not in list"
     ]
    }
   ],
   "source": [
    "# Create NN-Unet data set\n",
    "def create_dataset(input_data):\n",
    "    create_folder_structure(os.path.join(target_base, task_name))\n",
    "\n",
    "    num_masks = len(masks) \n",
    "    \n",
    "    fem_head_index_in_list = int(masks.index(\"FemoralHead\")) if \"FemoralHead\" in masks else -1\n",
    "\n",
    "    for patient_name in get_train_set():\n",
    "        print(patient_name)\n",
    "        combine_femoral_heads = False\n",
    "        patient_path = os.path.join(input_data,  patient_name)\n",
    "        image_path = os.path.join(patient_path,  \"image.nii.gz\")\n",
    "\n",
    "        label_map = np.array([], dtype=np.dtype('u1') )\n",
    "        for (i,mask) in enumerate(masks):\n",
    "            if (mask == \"FemoralHead\"):\n",
    "                mask_path = os.path.join(input_data, patient_name,  \"mask_FemoralHead_L.nii.gz\")\n",
    "                combine_femoral_heads = True\n",
    "            else:\n",
    "                mask_path = os.path.join(input_data, patient_name,  \"mask_\" + mask + \".nii.gz\")\n",
    "\n",
    "            try:\n",
    "            \n",
    "                img = nib.load(mask_path)\n",
    "                img_array = np.array(img.dataobj)\n",
    "                if(i == 0):\n",
    "                    img_header=img.header.copy()\n",
    "                    label_map = np.zeros(img_array.shape, dtype=np.dtype('u1') )\n",
    "            \n",
    "                # Assumes no overlapping labels i.e labels set in order of the mask list. \n",
    "                # Place substructures last in this list so they are not overwritten\n",
    "                if ((i == num_masks - 1) and combine_femoral_heads):\n",
    "                    label_map[img_array != 0] = fem_head_index_in_list + 1\n",
    "                else:\n",
    "                    label_map[img_array != 0] = i+1 \n",
    "\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "           \n",
    "        ni_img = nib.Nifti1Image(label_map, None, header=img_header)\n",
    "\n",
    "        shutil.copyfile(image_path, os.path.join(target_base, task_name, \"imagesTr\",  patient_name + \"_0000.nii.gz\"))\n",
    "        nib.save(ni_img, os.path.join(target_base, task_name,  \"labelsTr\", patient_name + \".nii.gz\"))\n",
    "        #print(label_map[label_map != 0][0])\n",
    "            \n",
    "                \n",
    "    for patient_name in get_test_set():\n",
    "        print(patient_name)\n",
    "        patient_path = os.path.join(input_data,  patient_name)\n",
    "        image_path = os.path.join(patient_path,  \"image.nii.gz\")\n",
    "        shutil.copyfile(image_path, os.path.join(target_base, task_name, \"imagesTs\",  patient_name + \"_0000.nii.gz\"))\n",
    "\n",
    "#create_dataset(data_dir)\n",
    "create_dataset(\"/vol/bitbucket/djk18/dataset/downsample_2m_isotropic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataaset function from https://github.com/MIC-DKFZ/nnUNet/blob/master/nnunetv2/dataset_conversion/generate_dataset_json.py\n",
    "def generate_dataset_json(output_folder: str,\n",
    "                          channel_names: dict,\n",
    "                          labels: dict,\n",
    "                          num_training_cases: int,\n",
    "                          file_ending: str,\n",
    "                          regions_class_order: Tuple[int, ...] = None,\n",
    "                          dataset_name: str = None, reference: str = None, release: str = None, license: str = None,\n",
    "                          description: str = None,\n",
    "                          overwrite_image_reader_writer: str = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Generates a dataset.json file in the output folder\n",
    "    channel_names:\n",
    "        Channel names must map the index to the name of the channel, example:\n",
    "        {\n",
    "            0: 'T1',\n",
    "            1: 'CT'\n",
    "        }\n",
    "        Note that the channel names may influence the normalization scheme!! Learn more in the documentation.\n",
    "    labels:\n",
    "        This will tell nnU-Net what labels to expect. Important: This will also determine whether you use region-based training or not.\n",
    "        Example regular labels:\n",
    "        {\n",
    "            'background': 0,\n",
    "            'left atrium': 1,\n",
    "            'some other label': 2\n",
    "        }\n",
    "        Example region-based training:\n",
    "        {\n",
    "            'background': 0,\n",
    "            'whole tumor': (1, 2, 3),\n",
    "            'tumor core': (2, 3),\n",
    "            'enhancing tumor': 3\n",
    "        }\n",
    "        Remember that nnU-Net expects consecutive values for labels! nnU-Net also expects 0 to be background!\n",
    "    num_training_cases: is used to double check all cases are there!\n",
    "    file_ending: needed for finding the files correctly. IMPORTANT! File endings must match between images and\n",
    "    segmentations!\n",
    "    dataset_name, reference, release, license, description: self-explanatory and not used by nnU-Net. Just for\n",
    "    completeness and as a reminder that these would be great!\n",
    "    overwrite_image_reader_writer: If you need a special IO class for your dataset you can derive it from\n",
    "    BaseReaderWriter, place it into nnunet.imageio and reference it here by name\n",
    "    kwargs: whatever you put here will be placed in the dataset.json as well\n",
    "    \"\"\"\n",
    "    has_regions: bool = any([isinstance(i, (tuple, list)) and len(i) > 1 for i in labels.values()])\n",
    "    if has_regions:\n",
    "        assert regions_class_order is not None, f\"You have defined regions but regions_class_order is not set. \" \\\n",
    "                                                f\"You need that.\"\n",
    "    # channel names need strings as keys\n",
    "    keys = list(channel_names.keys())\n",
    "    for k in keys:\n",
    "        if not isinstance(k, str):\n",
    "            channel_names[str(k)] = channel_names[k]\n",
    "            del channel_names[k]\n",
    "\n",
    "    # labels need ints as values\n",
    "    for l in labels.keys():\n",
    "        value = labels[l]\n",
    "        if isinstance(value, (tuple, list)):\n",
    "            value = tuple([int(i) for i in value])\n",
    "            labels[l] = value\n",
    "        else:\n",
    "            labels[l] = int(labels[l])\n",
    "\n",
    "    dataset_json = {\n",
    "        'channel_names': channel_names,  \n",
    "        'labels': labels,\n",
    "        'numTraining': num_training_cases,\n",
    "        'file_ending': file_ending,\n",
    "    }\n",
    "\n",
    "    if dataset_name is not None:\n",
    "        dataset_json['name'] = dataset_name\n",
    "    if reference is not None:\n",
    "        dataset_json['reference'] = reference\n",
    "    if release is not None:\n",
    "        dataset_json['release'] = release\n",
    "    if license is not None:\n",
    "        dataset_json['licence'] = license\n",
    "    if description is not None:\n",
    "        dataset_json['description'] = description\n",
    "    if overwrite_image_reader_writer is not None:\n",
    "        dataset_json['overwrite_image_reader_writer'] = overwrite_image_reader_writer\n",
    "    if regions_class_order is not None:\n",
    "        dataset_json['regions_class_order'] = regions_class_order\n",
    "\n",
    "    dataset_json.update(kwargs)\n",
    "\n",
    "    save_json(dataset_json, join(output_folder, 'dataset.json'), sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset506\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_base     = join(\"/vol/bitbucket/djk18/nnUnet_models/nnUNet_raw_data/\", task_name)\n",
    "target_imagesTr = join(target_base, \"imagesTr\")\n",
    "target_imagesTs = join(target_base, \"imagesTs\")\n",
    "target_labelsTs = join(target_base, \"labelsTs\")\n",
    "target_labelsTr = join(target_base, \"labelsTr\")\n",
    "\n",
    "# What is modality?\n",
    "#generate_dataset_json_old(join(target_base, 'dataset.json'), target_imagesTr, target_imagesTs, ('M'),\n",
    "#                          labels={0: 'background', 1: \"Bones\", 2: \"FemoralHead_L\", 3: \"FemoralHead_R\", 4: \"Bladder\", 5: \"Anorectum\", 6: \"Bowel-bag\", 7: \"Bowel-loops\", 8: \"CTVp\"}, dataset_name=task_name, license='Academic use')\n",
    "#, dataset_name=task_name, license='Academic use'\n",
    "\n",
    "\n",
    "def dataset503_json():\n",
    "     generate_dataset_json(target_base,\n",
    "                          channel_names={0: 'CT'},\n",
    "                          labels={\n",
    "                                'background': 0,\n",
    "                                'Bones': 1,\n",
    "                                'FemoralHead_L': 2,\n",
    "                                'FemoralHead_R': 3,\n",
    "                                'Bladder': 4,\n",
    "                                \"Anorectum\": 5, \n",
    "                                \"Bowel-bag\": (6,7), \n",
    "                                \"Bowel-loops\": (7,), \n",
    "                                \"CTVp\": 8\n",
    "                            },\n",
    "                          num_training_cases=70,\n",
    "                          file_ending='.nii.gz',\n",
    "                          regions_class_order=(1,2,3,4,5,6,7,8),\n",
    "                          dataset_name=task_name,\n",
    "                          license='MIT',\n",
    "                          dataset_release='1.0')\n",
    "     \n",
    "def dataset504_json():\n",
    "    generate_dataset_json(target_base,\n",
    "                          channel_names={0: 'CT'},\n",
    "                          labels={\n",
    "                                'background': 0,\n",
    "                                'Bones': 1,\n",
    "                                'FemoralHead_L': 2,\n",
    "                                'FemoralHead_R': 3,\n",
    "                                'Bladder': 4,\n",
    "                                \"Anorectum\": 5, \n",
    "                                \"Bowel-bag\": 6, \n",
    "                                \"Bowel-loops\": 7, \n",
    "                                \"CTVp\": 8\n",
    "                            },\n",
    "                          num_training_cases=80,\n",
    "                          file_ending='.nii.gz',\n",
    "                          dataset_name=task_name,\n",
    "                          license='MIT',\n",
    "                          dataset_release='1.0')\n",
    "\n",
    "def dataset505_json():\n",
    "    generate_dataset_json(target_base,\n",
    "                          channel_names={0: 'CT'},\n",
    "                          labels={\n",
    "                                'background': 0,\n",
    "                                'Bones': 1,\n",
    "                                'FemoralHead' : 2,\n",
    "                                'Bladder': 3,\n",
    "                                \"Anorectum\": 4, \n",
    "                                \"Bowel-bag\": 5, \n",
    "                                \"Bowel-loops\": 6, \n",
    "                                \"CTVp\": 7\n",
    "                            },\n",
    "                          num_training_cases=80,\n",
    "                          file_ending='.nii.gz',\n",
    "                          dataset_name=task_name,\n",
    "                          license='MIT',\n",
    "                          dataset_release='1.0')\n",
    "    \n",
    "def dataset506_json():\n",
    "    generate_dataset_json(target_base,\n",
    "                          channel_names={0: 'CT'},\n",
    "                          labels={\n",
    "                                'background': 0,\n",
    "                                'Bones': (1, 2),\n",
    "                                'FemoralHead': 2,\n",
    "                                'Bladder': 3,\n",
    "                                \"Anorectum\": 4, \n",
    "                                \"Bowel-bag\": (5,6), \n",
    "                                \"Bowel-loops\": 6, \n",
    "                                \"CTVp\": 7\n",
    "                            },\n",
    "                          num_training_cases=80,\n",
    "                          file_ending='.nii.gz',\n",
    "                          regions_class_order=(1,2,3,4,5,6,7),\n",
    "                          dataset_name=task_name,\n",
    "                          license='MIT',\n",
    "                          dataset_release='1.0')\n",
    "\n",
    "function_map = {\n",
    "    \"Dataset503\" : dataset503_json,\n",
    "    \"Dataset504\" : dataset504_json,\n",
    "    \"Dataset505\" : dataset505_json,\n",
    "    \"Dataset506\" : dataset506_json\n",
    "\n",
    "}\n",
    "\n",
    "if task_name in function_map:\n",
    "    print(task_name)\n",
    "    function = function_map[task_name]\n",
    "    function()\n",
    "else:\n",
    "    print(\"Taskname not in function map\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contouring",
   "language": "python",
   "name": "contouring"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
